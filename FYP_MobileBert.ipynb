{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/AlexXPZhu/XMUM-FYP-Code/blob/main/FYP_MobileBert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_a7W2u5XmD9t"
   },
   "outputs": [],
   "source": [
    "# 安装依赖\n",
    "!pip install transformers datasets torch scikit-learn accelerate -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "erOXOWsVthOu",
    "outputId": "8e7d1ec0-bf2e-4903-a921-c7599abfd57e"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# 访问云盘数据集\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4BCg1U_wtkGx",
    "outputId": "88369f01-5e9c-4dac-f3eb-648856c1654e"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Wed Dec  3 17:49:02 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   58C    P0             26W /   70W |    2084MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "# 检查是不是在gpu上面运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mLGzn0JVtl8C",
    "outputId": "f8bc5053-84f7-4a22-9728-4253e08f987f"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# 检查是不是链接到了cuda\n",
    "import torch\n",
    "print(f\"Using device: {torch.device('cuda' if torch.cuda.is_available() else 'cpu')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tHEpCOr2vxrQ"
   },
   "outputs": [],
   "source": [
    "# 导入模型\n",
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForPreTraining\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/mobilebert-uncased\")\n",
    "model = AutoModelForPreTraining.from_pretrained(\"google/mobilebert-uncased\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0-TAv40VElbV",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208,
     "referenced_widgets": [
      "a07626bf09d749b38ad530937edc581b",
      "ec0407904eeb4aa8bc401e23d07c3e37",
      "78188e58bda44e24b0c604a0cc8c03a4",
      "966d36c88a6849f0837d1dd01464aa2c",
      "53f825f1639849d09efe0973aa60d8ef",
      "aa51106096ef4026bc4033b11de19c96",
      "d3081e764da44faca1606d19d5bc280e",
      "8f779ff1307b422dbd23adff26ff7c68",
      "27e60d3a687c45d4a5c1040fdac4c835",
      "af30166bb0854e7c9d964c0e051ed956",
      "9682c29465a0414ba64b09a510081f66",
      "a593088ae9924ef3bd7c435d8b23f9f0",
      "cef133a6c99a4f8f9c22203f9f0109cd",
      "53063cc0bcb44f46a8b5adb1729b7066",
      "f410f1cbdffd4eb9b25d86605a6cf870",
      "912a1002cd7e4b78afdf48960acff2e8",
      "d0c03222a58d4900a39a809694f4e19d",
      "821c2a8d0baa4470b385393890136df8",
      "175367b0ead4453a9a0547a83a7804cc",
      "8d3fc3d15af046d2bcbf111aee9bc465",
      "5663cb1b05914d4fbb2881175590d65f",
      "3cd5fa8f43804ab3911782a45eb25745",
      "509a52d9d12e4a8788b40ec6dfeb305d",
      "32c0e326a9654e8cb97a4c9c5b48b385",
      "8e43050867314f58b9140da0c2ab0968",
      "acbc8e796e0945c69de7b0e88241623b",
      "5ac3fef07e8d4c8d904924aa0b16e755",
      "d112ecca8e4f4b11a191dd7fb7745715",
      "9dec37d2a5b043e6918ba65234dafa76",
      "470305233c5248878ca6920c624f000f",
      "c7ac29b153fb4dc1b166c00ace0608bc",
      "3c20f1659574495c8d1f5bb014aa1208",
      "660039c11604459d849d9c5015748a8e"
     ]
    },
    "outputId": "14599339-596c-4e5f-b067-c0f110b94dd2"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/39827 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a07626bf09d749b38ad530937edc581b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Asking to pad to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no padding.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/8535 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a593088ae9924ef3bd7c435d8b23f9f0"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/8535 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "509a52d9d12e4a8788b40ec6dfeb305d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "✅ 数据处理完成！可以开始训练了。\n",
      "现在的列名: ['Sentence', 'labels', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# 1. 载入数据\n",
    "file_path = '/content/drive/MyDrive/FYP/merged_data.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 2. 划分数据\n",
    "train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42, stratify=df[\"Label\"])\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42, stratify=temp_df[\"Label\"])\n",
    "\n",
    "# 3. 转换为 Hugging Face Dataset\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "val_dataset = Dataset.from_pandas(val_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "# ================= 关键修正步骤 =================\n",
    "\n",
    "# 4. [必须执行] 改名：因为你重置了环境，现在的列名又是 \"Label\" 了\n",
    "# 如果这一步报错说 \"Label\" 不存在，说明你可能重复运行了，但在重置环境后，这步是必须的。\n",
    "train_dataset = train_dataset.rename_column(\"Label\", \"labels\")\n",
    "val_dataset = val_dataset.rename_column(\"Label\", \"labels\")\n",
    "test_dataset = test_dataset.rename_column(\"Label\", \"labels\")\n",
    "\n",
    "# 5. [必须执行] 分词：这一步生成 input_ids 和 attention_mask\n",
    "# 加载分词器 (假设你用的是 MobileBERT，如果是其他模型请替换)\n",
    "model_checkpoint = \"google/mobilebert-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    # 注意：这里使用的是 \"Sentence\" 列，对应你报错信息里的列名\n",
    "    return tokenizer(examples[\"Sentence\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "# 批量处理\n",
    "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_val = val_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_test = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# 6. [最后一步] 设置格式\n",
    "# 只有在分词之后，这些列才真正存在\n",
    "# 这里的 columns 列表要根据 tokenizer 实际生成的列来写，通常是这三个+labels\n",
    "columns_to_keep = [\"input_ids\", \"attention_mask\", \"labels\"]\n",
    "if \"token_type_ids\" in tokenized_train.column_names:\n",
    "    columns_to_keep.append(\"token_type_ids\")\n",
    "\n",
    "tokenized_train.set_format(\"torch\", columns=columns_to_keep)\n",
    "tokenized_val.set_format(\"torch\", columns=columns_to_keep)\n",
    "tokenized_test.set_format(\"torch\", columns=columns_to_keep)\n",
    "\n",
    "print(\"✅ 数据处理完成！可以开始训练了。\")\n",
    "print(\"现在的列名:\", tokenized_train.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AzxzTiKs9i9A",
    "outputId": "c976d2b4-8e67-48ab-894f-3a89e362b5ae"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: evaluate in /usr/local/lib/python3.12/dist-packages (0.4.6)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.0.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.0.2)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate) (3.6.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.36.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from evaluate) (25.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (3.20.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2025.11.12)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p7xUAuq_8wga"
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "import os\n",
    "import numpy as np\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification, # 注意这里换成了分类模型\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170,
     "referenced_widgets": [
      "1771282c05144f34957e2ed00c8e1b18",
      "bc5b3f1041d943b89618bb82f6cfab93",
      "99867e5175eb411a96b9e170b08ab541",
      "71047952fb2a4c2a85fc829414f6fae9",
      "7684612b370e4e369c14ecec7ba15ad9",
      "fc21cbfe4b92487e86ca892da8479838",
      "e251c072573b4409ae40670c9c2eabd4",
      "573a353b1e584828bbe119c272c7ccfc",
      "5fa36edd560740d4bffe321c81abb396",
      "d0f5de5f6bb9409fbdc2158fd5633460",
      "48f4f810aedc4dcba3c02a5e8fa7e9e0",
      "dda61954a0fa4a2193067c7b08e0bc90",
      "f501ce0e10d745eabeedaa32d1503984",
      "a12f45194d6a425aa44f12ae755d15f9",
      "9808ec0cf10443739667eba33249e0a0",
      "5e4cf2a024f2458985140ca0c95a1549",
      "0256f7788a5d4e92a29ac1e39a80dbdd",
      "8a933ae8b01e49dfae2853172d152c7d",
      "58ee37d5cb0b45afafa69234ec4b4469",
      "f1e61257e2dc41aeabad3c48cccb67e3",
      "dc6c96d3da0c4a81ab8f697088fa7321",
      "3a57a13625d8474a836e3f50ac60ede3",
      "398fd5a866dc4331b74f9b0cba18c188",
      "95a6ef92a06e420a92148aeee030bdd1",
      "9d3e8b8315234edaa16bf011f8355c9b",
      "dc113ec3ad6a43fb8b2955ed7b0bbbe5",
      "31e46752610e4e279c13c813e617c999",
      "c1632ab74904479080cd81ecefbd0a56",
      "a7a5b7f9e40c411fb2859086771bcf59",
      "bfc1476ff2e7407593685126a0a7fc3b",
      "41d3fc9f4c6e4fbca24fb5bb7999e649",
      "4eece5a3971248729c00764532d6c250",
      "41175c500d1246dd955f183d6f4a0f32"
     ]
    },
    "id": "FEx2YWFR9G1E",
    "outputId": "86cc9e50-06e1-4136-fe02-5940de3589d2"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/39827 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1771282c05144f34957e2ed00c8e1b18"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/8535 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dda61954a0fa4a2193067c7b08e0bc90"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/8535 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "398fd5a866dc4331b74f9b0cba18c188"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of MobileBertForSequenceClassification were not initialized from the model checkpoint at google/mobilebert-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------------------\n",
    "# 1. 准备工作（假设上面的代码已经运行，datasets 已创建）\n",
    "# ----------------------------------------------------------------\n",
    "\n",
    "# 确定标签数量（假设你的标签是 0, 1, 2... 这样的数字）\n",
    "num_labels = len(df[\"Label\"].unique())\n",
    "\n",
    "# 加载分词器\n",
    "model_checkpoint = \"google/mobilebert-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "# 数据预处理函数\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"Sentence\"],\n",
    "        padding=\"max_length\",  # 不够长补 0\n",
    "        truncation=True,       # 重点：超长就切掉！\n",
    "        max_length=128         # 重点：显式限制为 MobileBERT 的上限\n",
    "    )\n",
    "\n",
    "# 对数据集进行分词\n",
    "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_val = val_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_test = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# 2. 加载模型 (针对分类任务)\n",
    "# ----------------------------------------------------------------\n",
    "# MobileBERT 针对分类任务微调，而不是 PreTraining\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    num_labels=num_labels\n",
    ")\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# 3. 设置评估指标\n",
    "# ----------------------------------------------------------------\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 596
    },
    "id": "75Zyp_-P9I_m",
    "outputId": "0af8bded-8c7d-43c3-e32c-f09abde09679"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁▃▆█</td></tr><tr><td>train/global_step</td><td>▁▃▆█</td></tr><tr><td>train/grad_norm</td><td>█▁▁▁</td></tr><tr><td>train/learning_rate</td><td>█▆▃▁</td></tr><tr><td>train/loss</td><td>█▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>0.08032</td></tr><tr><td>train/global_step</td><td>200</td></tr><tr><td>train/grad_norm</td><td>0.02489</td></tr><tr><td>train/learning_rate</td><td>2e-05</td></tr><tr><td>train/loss</td><td>0.6057</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run-1</strong> at: <a href='https://wandb.ai/zxp1279839620-xiamen-university/mobilebert-finetuning/runs/4vnon3b2' target=\"_blank\">https://wandb.ai/zxp1279839620-xiamen-university/mobilebert-finetuning/runs/4vnon3b2</a><br> View project at: <a href='https://wandb.ai/zxp1279839620-xiamen-university/mobilebert-finetuning' target=\"_blank\">https://wandb.ai/zxp1279839620-xiamen-university/mobilebert-finetuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>./wandb/run-20251203_174610-4vnon3b2/logs</code>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20251203_175005-em2bsssh</code>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/zxp1279839620-xiamen-university/mobilebert-finetuning/runs/em2bsssh' target=\"_blank\">run-1</a></strong> to <a href='https://wandb.ai/zxp1279839620-xiamen-university/mobilebert-finetuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/zxp1279839620-xiamen-university/mobilebert-finetuning' target=\"_blank\">https://wandb.ai/zxp1279839620-xiamen-university/mobilebert-finetuning</a>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/zxp1279839620-xiamen-university/mobilebert-finetuning/runs/em2bsssh' target=\"_blank\">https://wandb.ai/zxp1279839620-xiamen-university/mobilebert-finetuning/runs/em2bsssh</a>"
      ]
     },
     "metadata": {}
    }
   ],
   "source": [
    "# ----------------------------------------------------------------\n",
    "# 4. 配置训练参数 (重点：wandb 设置)\n",
    "# ----------------------------------------------------------------\n",
    "# 初始化 wandb 项目\n",
    "wandb.init(project=\"mobilebert-finetuning\", name=\"run-1\")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results-2025_12_3\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",  # 每个 epoch 结束后评估 (修复：将 evaluation_strategy 修改为 eval_strategy)\n",
    "    save_strategy=\"epoch\",        # 每个 epoch 结束后保存 checkpoint\n",
    "    load_best_model_at_end=True,  # 训练结束时加载验证集表现最好的模型\n",
    "    report_to=\"wandb\",            # 关键：将指标发送到 wandb\n",
    "    logging_steps=50,             # 每50步记录一次日志\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pHhG75tI9N1B",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "outputId": "977326c9-3606-4367-a9dc-f03d25292acd"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/tmp/ipython-input-1683293827.py:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "开始训练...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7470' max='7470' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7470/7470 26:13, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.017238</td>\n",
       "      <td>0.997774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.061509</td>\n",
       "      <td>0.998360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046089</td>\n",
       "      <td>0.998711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TrainOutput(global_step=7470, training_loss=1799.28196317354, metrics={'train_runtime': 1574.723, 'train_samples_per_second': 75.874, 'train_steps_per_second': 4.744, 'total_flos': 1873119198205440.0, 'train_loss': 1799.28196317354, 'epoch': 3.0})"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "# ----------------------------------------------------------------\n",
    "# 5. 初始化 Trainer 并开始训练\n",
    "# ----------------------------------------------------------------\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_val,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "print(\"开始训练...\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_lEdBNbTSKp8",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "7fc14644-754c-4c8f-cca0-7f173e9e5e8c"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "正在保存模型到 ./final_model_output ...\n",
      "正在保存 Tokenizer 到 ./final_model_output ...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (final_model_output)... Done. 0.4s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "✅ 模型和 Tokenizer 已上传到 WandB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 1. 定义一个干净的保存目录（不要直接用 output_dir，因为它里面可能有很多 checkpoint 文件夹）\n",
    "save_directory = \"./final_model_output\"\n",
    "\n",
    "# 2. 保存模型 (这会保存 config.json 和 pytorch_model.bin/model.safetensors)\n",
    "print(f\"正在保存模型到 {save_directory} ...\")\n",
    "trainer.save_model(save_directory)\n",
    "\n",
    "# 3. 【关键步骤】保存 Tokenizer\n",
    "# 这会保存 vocab.txt, tokenizer.json, special_tokens_map.json 等必要文件\n",
    "print(f\"正在保存 Tokenizer 到 {save_directory} ...\")\n",
    "tokenizer.save_pretrained(save_directory)\n",
    "\n",
    "# 4. (可选) 上传到 WandB\n",
    "# 这样你的 artifact 里就会同时包含模型权重和分词器，缺一不可\n",
    "import wandb\n",
    "if wandb.run is not None:\n",
    "    artifact = wandb.Artifact(\n",
    "        name=\"mobilebert_finetuned\",\n",
    "        type=\"model\",\n",
    "        description=\"Fine-tuned MobileBERT with tokenizer\"\n",
    "    )\n",
    "    artifact.add_dir(save_directory)\n",
    "    wandb.log_artifact(artifact)\n",
    "    print(\"✅ 模型和 Tokenizer 已上传到 WandB\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "authorship_tag": "ABX9TyPQM0sbEy9qd5ml9/4S5MZo",
   "include_colab_link": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
